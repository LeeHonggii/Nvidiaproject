{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from scipy.spatial import procrustes\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_for_faces(image_path):\n",
    "    app = FaceAnalysis(allowed_modules=[\"detection\", \"landmark_2d_106\"], providers=[\"CUDAExecutionProvider\"])\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    \n",
    "    faces_data = app.get(img)\n",
    "    faces_landmarks = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for face in faces_data:\n",
    "        if \"landmark_2d_106\" in face:\n",
    "            lmk = face[\"landmark_2d_106\"]\n",
    "            bbox = face[\"bbox\"].astype(np.int32)\n",
    "            faces_landmarks.append(np.round(lmk).astype(np.int64))\n",
    "            bounding_boxes.append(bbox)\n",
    "    \n",
    "    return faces_landmarks, bounding_boxes, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distances(landmarks):\n",
    "    distances = {}\n",
    "    # 눈과 눈썹 사이의 거리\n",
    "    distances['eye_to_eyebrow_left'] = np.linalg.norm(landmarks[37] - landmarks[19])\n",
    "    distances['eye_to_eyebrow_right'] = np.linalg.norm(landmarks[46] - landmarks[24])\n",
    "\n",
    "    # 눈의 가로 길이\n",
    "    distances['eye_width_left'] = np.linalg.norm(landmarks[36] - landmarks[39])\n",
    "    distances['eye_width_right'] = np.linalg.norm(landmarks[42] - landmarks[45])\n",
    "\n",
    "    # 코의 길이\n",
    "    distances['nose_length'] = np.linalg.norm(landmarks[30] - landmarks[33])\n",
    "\n",
    "    # 입과 코 사이의 거리\n",
    "    distances['nose_to_mouth'] = np.linalg.norm(landmarks[33] - landmarks[51])\n",
    "\n",
    "    # 입술의 너비\n",
    "    distances['mouth_width'] = np.linalg.norm(landmarks[48] - landmarks[54])\n",
    "\n",
    "    # 이마의 높이 (이마 중앙에서 눈썹 중앙까지)\n",
    "    distances['forehead_height'] = np.linalg.norm(landmarks[27] - landmarks[8])\n",
    "\n",
    "    # 턱선의 길이 (턱 끝에서 귀 바로 아래까지)\n",
    "    distances['jawline_length_left'] = np.linalg.norm(landmarks[5] - landmarks[8])\n",
    "    distances['jawline_length_right'] = np.linalg.norm(landmarks[11] - landmarks[8])\n",
    "\n",
    "    # 이마의 너비 (이마 양 끝)\n",
    "    distances['forehead_width'] = np.linalg.norm(landmarks[0] - landmarks[16])\n",
    "\n",
    "    # 얼굴의 높이 (이마 중앙에서 턱 끝까지)\n",
    "    distances['face_height'] = np.linalg.norm(landmarks[27] - landmarks[8])\n",
    "\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces_landmarks(faces_landmarks):\n",
    "    results = []\n",
    "    print(\"Procrustes disparity results for all possible face matches:\")\n",
    "    for idx1, lmk1 in enumerate(faces_landmarks):\n",
    "        for idx2, lmk2 in enumerate(faces_landmarks):\n",
    "            if idx1 != idx2:  # 자기 자신과의 비교를 제외\n",
    "                mtx1, mtx2, disparity = procrustes(lmk1, lmk2)\n",
    "                results.append((idx1, idx2, disparity))\n",
    "                print(f\"Face {idx1} vs Face {idx2}: Disparity = {disparity:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_features(landmarks1, landmarks2):\n",
    "    distances1 = calculate_distances(landmarks1)\n",
    "    distances2 = calculate_distances(landmarks2)\n",
    "    results = {}\n",
    "    for key in distances1:\n",
    "        # 각 특징 거리 차이를 비교\n",
    "        disparity = abs(distances1[key] - distances2[key])\n",
    "        results[key] = disparity\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matching_faces(image1, landmarks1, bounding_boxes1, image2, landmarks2, bounding_boxes2, matches):\n",
    "    pil_image1 = Image.fromarray(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "    pil_image2 = Image.fromarray(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "    draw1 = ImageDraw.Draw(pil_image1)\n",
    "    draw2 = ImageDraw.Draw(pil_image2)\n",
    "\n",
    "    # Load a font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    color = (255, 0, 0)  # Set a color for the bounding box and landmarks\n",
    "    point_radius = 2\n",
    "    \n",
    "    for idx1, (landmarks, bbox) in enumerate(zip(landmarks1, bounding_boxes1)):\n",
    "        for point in landmarks:\n",
    "            draw1.ellipse([point[0]-point_radius, point[1]-point_radius, point[0]+point_radius, point[1]+point_radius], fill=color)\n",
    "        draw1.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]], outline=color, width=2)\n",
    "        draw1.text((bbox[0], bbox[1] - 20), f\"Face {idx1}\", fill=(255, 255, 255), font=font)\n",
    "        \n",
    "    for idx2, (landmarks, bbox) in enumerate(zip(landmarks2, bounding_boxes2)):\n",
    "        for point in landmarks:\n",
    "            draw2.ellipse([point[0]-point_radius, point[1]-point_radius, point[0]+point_radius, point[1]+point_radius], fill=color)\n",
    "        draw2.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]], outline=color, width=2)\n",
    "        draw2.text((bbox[0], bbox[1] - 20), f\"Face {idx2}\", fill=(255, 255, 255), font=font)\n",
    "\n",
    "    # Highlight matching faces with a different color\n",
    "    match_color = (0, 255, 0)\n",
    "    for match in matches:\n",
    "        idx1, idx2, disparity = match\n",
    "        if disparity < 0.05:  # Threshold for matching, can be adjusted\n",
    "            bbox1 = bounding_boxes1[idx1]\n",
    "            bbox2 = bounding_boxes2[idx2]\n",
    "            draw1.rectangle([bbox1[0], bbox1[1], bbox1[2], bbox1[3]], outline=match_color, width=3)\n",
    "            draw2.rectangle([bbox2[0], bbox2[1], bbox2[2], bbox2[3]], outline=match_color, width=3)\n",
    "\n",
    "    pil_image1.show()\n",
    "    pil_image2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "compare_faces_landmarks() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m landmarks2, boxes2, img2 \u001b[38;5;241m=\u001b[39m process_image_for_faces(img_path2)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m landmarks1 \u001b[38;5;129;01mand\u001b[39;00m landmarks2:\n\u001b[1;32m----> 9\u001b[0m     comparison_results \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_faces_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlandmarks1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandmarks2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     draw_matching_faces(img1, landmarks1, boxes1, img2, landmarks2, boxes2, comparison_results)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: compare_faces_landmarks() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Paths to the images\n",
    "img_path1 = \"data/aespa1.jpg\"\n",
    "img_path2 = \"data/aespa2.jpg\"\n",
    "\n",
    "landmarks1, boxes1, img1 = process_image_for_faces(img_path1)\n",
    "landmarks2, boxes2, img2 = process_image_for_faces(img_path2)\n",
    "\n",
    "if landmarks1 and landmarks2:\n",
    "    comparison_results = compare_faces_landmarks(landmarks1, landmarks2)\n",
    "    draw_matching_faces(img1, landmarks1, boxes1, img2, landmarks2, boxes2, comparison_results)\n",
    "else:\n",
    "    print(\"Landmarks were not detected in one or both images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature disparities between two faces:\n",
      "eye_to_eyebrow_left: 10.1794\n",
      "eye_to_eyebrow_right: 16.8172\n",
      "eye_width_left: 0.5176\n",
      "eye_width_right: 0.0000\n",
      "nose_length: 6.8069\n",
      "nose_to_mouth: 0.9443\n",
      "mouth_width: 8.0474\n",
      "forehead_height: 14.5859\n",
      "jawline_length_left: 3.8925\n",
      "jawline_length_right: 13.0166\n",
      "forehead_width: 8.1880\n",
      "face_height: 14.5859\n"
     ]
    }
   ],
   "source": [
    "features_comparison = compare_all_features(landmarks1[0], landmarks2[0])\n",
    "print(\"Feature disparities between two faces:\")\n",
    "for feature, disparity in features_comparison.items():\n",
    "    print(f\"{feature}: {disparity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Similarity between Face 0 in Image 1 and Face 0 in Image 2: 0.4435\n",
      "Similarity between Face 1 in Image 1 and Face 0 in Image 2: 0.3970\n",
      "Similarity between Face 2 in Image 1 and Face 0 in Image 2: 0.8123\n",
      "Similarity between Face 3 in Image 1 and Face 0 in Image 2: 0.1215\n",
      "Similarity between Face 4 in Image 1 and Face 0 in Image 2: 0.0000\n",
      "Highest similarity for Face 0 in Image 1: 0.4435\n",
      "Highest similarity for Face 1 in Image 1: 0.3970\n",
      "Highest similarity for Face 2 in Image 1: 0.8123\n",
      "Highest similarity for Face 3 in Image 1: 0.1215\n",
      "Highest similarity for Face 4 in Image 1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def process_image_for_faces(image_path):\n",
    "    app = FaceAnalysis(allowed_modules=[\"detection\", \"landmark_2d_106\"], providers=[\"CUDAExecutionProvider\"])\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    \n",
    "    faces_data = app.get(img)\n",
    "    faces_landmarks = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for face in faces_data:\n",
    "        lmk = face[\"landmark_2d_106\"]\n",
    "        bbox = face[\"bbox\"].astype(np.int32)\n",
    "        faces_landmarks.append(np.round(lmk).astype(np.int64))\n",
    "        bounding_boxes.append(bbox)\n",
    "    \n",
    "    return faces_landmarks, bounding_boxes, img\n",
    "\n",
    "def calculate_distances(landmarks):\n",
    "    distances = {\n",
    "        'eyebrow_length_left': np.linalg.norm(landmarks[46] - landmarks[43]),\n",
    "        'eyebrow_length_right': np.linalg.norm(landmarks[97] - landmarks[101]),\n",
    "        'eye_width_left': np.linalg.norm(landmarks[39] - landmarks[35]),\n",
    "        'eye_width_right': np.linalg.norm(landmarks[89] - landmarks[93]),\n",
    "        'nose_length': np.linalg.norm(landmarks[72] - landmarks[86]),\n",
    "        'nose_to_mouth': np.linalg.norm(landmarks[80] - landmarks[71]),\n",
    "        'mouth_width': np.linalg.norm(landmarks[52] - landmarks[61]),\n",
    "        'jawline_length_left': np.linalg.norm(landmarks[1] - landmarks[0]),\n",
    "        'jawline_length_right': np.linalg.norm(landmarks[17] - landmarks[0])\n",
    "    }\n",
    "    return distances\n",
    "\n",
    "def compare_all_faces_features(faces_landmarks1, faces_landmarks2):\n",
    "    all_results = {}\n",
    "    for idx1, lmk1 in enumerate(faces_landmarks1):\n",
    "        face_results = []\n",
    "        for idx2, lmk2 in enumerate(faces_landmarks2):\n",
    "            distances1 = calculate_distances(lmk1)\n",
    "            distances2 = calculate_distances(lmk2)\n",
    "            disparities = {key: abs(distances1[key] - distances2[key]) for key in distances1}\n",
    "            similarity = calculate_similarity(disparities)\n",
    "            face_results.append(similarity)\n",
    "            print(f\"Similarity between Face {idx1} in Image 1 and Face {idx2} in Image 2: {similarity:.4f}\")\n",
    "        all_results[idx1] = face_results\n",
    "    return all_results\n",
    "\n",
    "def calculate_similarity(disparities):\n",
    "    mean_disparity = np.mean(list(disparities.values()))\n",
    "    similarity = 1 - (mean_disparity / 10)\n",
    "    return max(0, min(similarity, 1))\n",
    "\n",
    "# Define the paths to the images\n",
    "img_path1 = \"data/aespa1.jpg\"\n",
    "img_path2 = \"data/aespa2.jpg\"\n",
    "\n",
    "# Process the images and extract landmarks and bounding boxes\n",
    "landmarks1, boxes1, img1 = process_image_for_faces(img_path1)\n",
    "landmarks2, boxes2, img2 = process_image_for_faces(img_path2)\n",
    "\n",
    "# Compare all faces across the two images if landmarks are detected\n",
    "if landmarks1 and landmarks2:\n",
    "    comparison_results = compare_all_faces_features(landmarks1, landmarks2)\n",
    "    for face_idx, similarities in comparison_results.items():\n",
    "        max_similarity = max(similarities)\n",
    "        print(f\"Highest similarity for Face {face_idx} in Image 1: {max_similarity:.4f}\")\n",
    "else:\n",
    "    print(\"Landmarks were not detected in one or both images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def process_image_for_faces(image_path):\n",
    "    app = FaceAnalysis(allowed_modules=[\"detection\", \"landmark_2d_106\"], providers=[\"CUDAExecutionProvider\"])\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    \n",
    "    faces_data = app.get(img)\n",
    "    faces_landmarks = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for face in faces_data:\n",
    "        lmk = face[\"landmark_2d_106\"]\n",
    "        bbox = face[\"bbox\"].astype(np.int32)\n",
    "        faces_landmarks.append(np.round(lmk).astype(np.int64))\n",
    "        bounding_boxes.append(bbox)\n",
    "    \n",
    "    return faces_landmarks, bounding_boxes, img\n",
    "\n",
    "def draw_faces_with_landmarks(image, faces_landmarks, bounding_boxes):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    # Load a font, or use PIL's default if unavailable\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 10)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # Draw each face's landmarks and bounding box\n",
    "    for idx, (landmarks, bbox) in enumerate(zip(faces_landmarks, bounding_boxes)):\n",
    "        draw.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]], outline=\"green\", width=2)\n",
    "        draw.text((bbox[0], bbox[1] - 10), f\"Face {idx}\", fill=\"yellow\", font=font)\n",
    "        for point_idx, point in enumerate(landmarks):\n",
    "            point_pos = (point[0] - 2, point[1] - 2, point[0] + 2, point[1] + 2)\n",
    "            draw.ellipse(point_pos, fill=\"red\")\n",
    "            draw.text((point[0] + 4, point[1]), str(point_idx), fill=\"blue\", font=font)\n",
    "\n",
    "    pil_image.show()\n",
    "\n",
    "# Define the paths to the images\n",
    "img_path1 = \"data/winter1.jpg\"\n",
    "\n",
    "# Process the image and extract landmarks and bounding boxes\n",
    "landmarks1, boxes1, img1 = process_image_for_faces(img_path1)\n",
    "\n",
    "# Draw landmarks on the image\n",
    "draw_faces_with_landmarks(img1, landmarks1, boxes1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
