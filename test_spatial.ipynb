{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from scipy.spatial import procrustes\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image_for_faces(image_path):\n",
    "    app = FaceAnalysis(allowed_modules=[\"detection\", \"landmark_2d_106\"], providers=[\"CUDAExecutionProvider\"])\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    \n",
    "    faces_data = app.get(img)\n",
    "    faces_landmarks = []\n",
    "    bounding_boxes = []\n",
    "    \n",
    "    for face in faces_data:\n",
    "        if \"landmark_2d_106\" in face:\n",
    "            lmk = face[\"landmark_2d_106\"]\n",
    "            bbox = face[\"bbox\"].astype(np.int32)\n",
    "            faces_landmarks.append(np.round(lmk).astype(np.int64))\n",
    "            bounding_boxes.append(bbox)\n",
    "    \n",
    "    return faces_landmarks, bounding_boxes, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces_landmarks(landmarks1, landmarks2):\n",
    "    results = []\n",
    "    print(\"Procrustes disparity results for all possible face matches:\")\n",
    "    for idx1, lmk1 in enumerate(landmarks1):\n",
    "        for idx2, lmk2 in enumerate(landmarks2):\n",
    "            mtx1, mtx2, disparity = procrustes(lmk1, lmk2)\n",
    "            results.append((idx1, idx2, disparity))\n",
    "            print(f\"Face {idx1} in Image 1 vs Face {idx2} in Image 2: Disparity = {disparity:.4f}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matching_faces(image1, landmarks1, bounding_boxes1, image2, landmarks2, bounding_boxes2, matches):\n",
    "    pil_image1 = Image.fromarray(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "    pil_image2 = Image.fromarray(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "    draw1 = ImageDraw.Draw(pil_image1)\n",
    "    draw2 = ImageDraw.Draw(pil_image2)\n",
    "\n",
    "    # Load a font\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 16)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    color = (255, 0, 0)  # Set a color for the bounding box and landmarks\n",
    "    point_radius = 2\n",
    "    \n",
    "    for idx1, (landmarks, bbox) in enumerate(zip(landmarks1, bounding_boxes1)):\n",
    "        for point in landmarks:\n",
    "            draw1.ellipse([point[0]-point_radius, point[1]-point_radius, point[0]+point_radius, point[1]+point_radius], fill=color)\n",
    "        draw1.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]], outline=color, width=2)\n",
    "        draw1.text((bbox[0], bbox[1] - 20), f\"Face {idx1}\", fill=(255, 255, 255), font=font)\n",
    "        \n",
    "    for idx2, (landmarks, bbox) in enumerate(zip(landmarks2, bounding_boxes2)):\n",
    "        for point in landmarks:\n",
    "            draw2.ellipse([point[0]-point_radius, point[1]-point_radius, point[0]+point_radius, point[1]+point_radius], fill=color)\n",
    "        draw2.rectangle([bbox[0], bbox[1], bbox[2], bbox[3]], outline=color, width=2)\n",
    "        draw2.text((bbox[0], bbox[1] - 20), f\"Face {idx2}\", fill=(255, 255, 255), font=font)\n",
    "\n",
    "    # Highlight matching faces with a different color\n",
    "    match_color = (0, 255, 0)\n",
    "    for match in matches:\n",
    "        idx1, idx2, disparity = match\n",
    "        if disparity < 0.05:  # Threshold for matching, can be adjusted\n",
    "            bbox1 = bounding_boxes1[idx1]\n",
    "            bbox2 = bounding_boxes2[idx2]\n",
    "            draw1.rectangle([bbox1[0], bbox1[1], bbox1[2], bbox1[3]], outline=match_color, width=3)\n",
    "            draw2.rectangle([bbox2[0], bbox2[1], bbox2[2], bbox2[3]], outline=match_color, width=3)\n",
    "\n",
    "    pil_image1.show()\n",
    "    pil_image2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Procrustes disparity results for all possible face matches:\n",
      "Face 0 in Image 1 vs Face 0 in Image 2: Disparity = 0.0566\n",
      "Face 0 in Image 1 vs Face 1 in Image 2: Disparity = 0.0530\n",
      "Face 0 in Image 1 vs Face 2 in Image 2: Disparity = 0.0538\n",
      "Face 0 in Image 1 vs Face 3 in Image 2: Disparity = 0.0642\n",
      "Face 1 in Image 1 vs Face 0 in Image 2: Disparity = 0.0517\n",
      "Face 1 in Image 1 vs Face 1 in Image 2: Disparity = 0.0470\n",
      "Face 1 in Image 1 vs Face 2 in Image 2: Disparity = 0.0465\n",
      "Face 1 in Image 1 vs Face 3 in Image 2: Disparity = 0.0565\n",
      "Face 2 in Image 1 vs Face 0 in Image 2: Disparity = 0.0488\n",
      "Face 2 in Image 1 vs Face 1 in Image 2: Disparity = 0.0459\n",
      "Face 2 in Image 1 vs Face 2 in Image 2: Disparity = 0.0463\n",
      "Face 2 in Image 1 vs Face 3 in Image 2: Disparity = 0.0551\n",
      "Face 3 in Image 1 vs Face 0 in Image 2: Disparity = 0.0507\n",
      "Face 3 in Image 1 vs Face 1 in Image 2: Disparity = 0.0466\n",
      "Face 3 in Image 1 vs Face 2 in Image 2: Disparity = 0.0489\n",
      "Face 3 in Image 1 vs Face 3 in Image 2: Disparity = 0.0582\n"
     ]
    }
   ],
   "source": [
    "# Paths to the images\n",
    "img_path1 = \"data/aespa4.jpg\"\n",
    "img_path2 = \"data/aespa5.jpg\"\n",
    "\n",
    "landmarks1, boxes1, img1 = process_image_for_faces(img_path1)\n",
    "landmarks2, boxes2, img2 = process_image_for_faces(img_path2)\n",
    "\n",
    "if landmarks1 and landmarks2:\n",
    "    comparison_results = compare_faces_landmarks(landmarks1, landmarks2)\n",
    "    draw_matching_faces(img1, landmarks1, boxes1, img2, landmarks2, boxes2, comparison_results)\n",
    "else:\n",
    "    print(\"Landmarks were not detected in one or both images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
