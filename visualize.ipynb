{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to output_with_face_centers_and_lines.jpg\n"
     ]
    }
   ],
   "source": [
    "# TODO : 전체 영상의 한명의 얼굴 위치만 찍기\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "def load_csv_data(file_paths):\n",
    "    all_face_positions = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, \"r\") as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            next(csvreader)  # Skip header\n",
    "            for row in csvreader:\n",
    "                frame, x, y, w, h, eye_point1, eye_point2 = row\n",
    "                all_face_positions.append((int(x), int(y), int(w), int(h)))\n",
    "    return all_face_positions\n",
    "\n",
    "\n",
    "def draw_face_centers_on_white_background(face_positions, image_size=(1080, 1920)):\n",
    "    # Create a white background image\n",
    "    white_background = np.ones((image_size[0], image_size[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Define lines based on the example dimensions\n",
    "    width, height = image_size[1], image_size[0]\n",
    "    line1_x = int(width * 0.35)\n",
    "    line2_x = int(width * 0.65)\n",
    "    line1_y = int(height * 0.25)\n",
    "    line2_y = int(height * 0.6)\n",
    "\n",
    "    # Draw lines (blue color #4BEEEE)\n",
    "    line_color = (235, 64, 52)\n",
    "    cv2.line(white_background, (line1_x, 0), (line1_x, height), line_color, 2)\n",
    "    cv2.line(white_background, (line2_x, 0), (line2_x, height), line_color, 2)\n",
    "    cv2.line(white_background, (0, line1_y), (width, line1_y), line_color, 2)\n",
    "    cv2.line(white_background, (0, line2_y), (width, line2_y), line_color, 2)\n",
    "\n",
    "    # Draw face centers (red color #EE4B4B)\n",
    "    circle_color = (66, 135, 245)\n",
    "    for x, y, w, h in face_positions:\n",
    "        if w > 0 and h > 0:  # Only draw for valid positions\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            cv2.circle(\n",
    "                white_background, (center_x, center_y), 5, circle_color, -1\n",
    "            )  # Draw red circle\n",
    "\n",
    "    output_image_path = \"output_with_face_centers_and_lines.jpg\"\n",
    "    cv2.imwrite(output_image_path, white_background)\n",
    "    print(f\"Image saved to {output_image_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "csv_files = [\n",
    "    \"output_ive_baddie_1.csv\",\n",
    "    \"output_ive_baddie_2.csv\",\n",
    "    \"output_ive_baddie_3.csv\",\n",
    "    \"output_ive_baddie_4.csv\",\n",
    "    \"output_ive_baddie_5.csv\",\n",
    "    \"output_ive_baddie_6.csv\",\n",
    "]  # Replace with your CSV file paths\n",
    "\n",
    "face_positions = load_csv_data(csv_files)\n",
    "draw_face_centers_on_white_background(face_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ive_baddie_1.mp4:   1%|▏         | 14/963 [00:02<02:51,  5.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 109\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    100\u001b[0m video_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_1.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_6.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    107\u001b[0m ]\n\u001b[1;32m--> 109\u001b[0m face_positions \u001b[38;5;241m=\u001b[39m \u001b[43mload_video_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m draw_face_centers_on_white_background(face_positions)\n",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m, in \u001b[0;36mload_video_data\u001b[1;34m(video_paths)\u001b[0m\n\u001b[0;32m     62\u001b[0m all_face_positions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_path \u001b[38;5;129;01min\u001b[39;00m video_paths:\n\u001b[1;32m---> 64\u001b[0m     face_positions, fps, total_frames, duration \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     all_face_positions\u001b[38;5;241m.\u001b[39mextend(face_positions)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_face_positions\n",
      "Cell \u001b[1;32mIn[3], line 41\u001b[0m, in \u001b[0;36mprocess_video\u001b[1;34m(video_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frame_count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m current_frame_positions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "File \u001b[1;32mc:\\Users\\hancomtst\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\insightface\\app\\face_analysis.py:59\u001b[0m, in \u001b[0;36mFaceAnalysis.get\u001b[1;34m(self, img, max_num)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, max_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m---> 59\u001b[0m     bboxes, kpss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmax_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bboxes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\hancomtst\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\insightface\\model_zoo\\retinaface.py:224\u001b[0m, in \u001b[0;36mRetinaFace.detect\u001b[1;34m(self, img, input_size, max_num, metric)\u001b[0m\n\u001b[0;32m    221\u001b[0m det_img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros( (input_size[\u001b[38;5;241m1\u001b[39m], input_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8 )\n\u001b[0;32m    222\u001b[0m det_img[:new_height, :new_width, :] \u001b[38;5;241m=\u001b[39m resized_img\n\u001b[1;32m--> 224\u001b[0m scores_list, bboxes_list, kpss_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdet_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(scores_list)\n\u001b[0;32m    227\u001b[0m scores_ravel \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\hancomtst\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\insightface\\model_zoo\\retinaface.py:151\u001b[0m, in \u001b[0;36mRetinaFace.forward\u001b[1;34m(self, img, threshold)\u001b[0m\n\u001b[0;32m    149\u001b[0m kpss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    150\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 151\u001b[0m blob \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblobFromImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_mean\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswapRB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m net_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_names, {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_name : blob})\n\u001b[0;32m    154\u001b[0m input_height \u001b[38;5;241m=\u001b[39m blob\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO : 전체 영상의 얼굴 포인트 찍기\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"No file found at {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Failed to open video file.\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps else 0\n",
    "\n",
    "    app = FaceAnalysis(\n",
    "        allowed_modules=[\"detection\", \"landmark_2d_106\"],\n",
    "        providers=[\"CUDAExecutionProvider\"],\n",
    "    )\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    frame_count = 0\n",
    "    face_positions = []\n",
    "\n",
    "    with tqdm(total=total_frames // 5, desc=os.path.basename(video_path)) as pbar:\n",
    "        while frame_count < total_frames:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            if frame_count % 5 != 0:\n",
    "                continue\n",
    "\n",
    "            faces = app.get(frame)\n",
    "            current_frame_positions = []\n",
    "\n",
    "            for face in faces:\n",
    "                bbox = face.bbox.astype(int)\n",
    "                current_frame_positions.append(\n",
    "                    (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "                )\n",
    "\n",
    "            if current_frame_positions:\n",
    "                face_positions.append(current_frame_positions)\n",
    "            else:\n",
    "                face_positions.append([(0, 0, 0, 0)])\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    return face_positions, fps, total_frames, duration\n",
    "\n",
    "\n",
    "def load_video_data(video_paths):\n",
    "    all_face_positions = []\n",
    "    for video_path in video_paths:\n",
    "        face_positions, fps, total_frames, duration = process_video(video_path)\n",
    "        all_face_positions.extend(face_positions)\n",
    "    return all_face_positions\n",
    "\n",
    "\n",
    "def draw_face_centers_on_white_background(face_positions, image_size=(1080, 1920)):\n",
    "    white_background = np.ones((image_size[0], image_size[1], 3), dtype=np.uint8) * 255\n",
    "\n",
    "    width, height = image_size[1], image_size[0]\n",
    "    line1_x = int(width * 0.35)\n",
    "    line2_x = int(width * 0.65)\n",
    "    line1_y = int(height * 0.25)\n",
    "    line2_y = int(height * 0.6)\n",
    "\n",
    "    line_color = (235, 64, 52)\n",
    "    cv2.line(white_background, (line1_x, 0), (line1_x, height), line_color, 2)\n",
    "    cv2.line(white_background, (line2_x, 0), (line2_x, height), line_color, 2)\n",
    "    cv2.line(white_background, (0, line1_y), (width, line1_y), line_color, 2)\n",
    "    cv2.line(white_background, (0, line2_y), (width, line2_y), line_color, 2)\n",
    "\n",
    "    circle_color = (66, 135, 245)\n",
    "    rect_color = (0, 0, 0)\n",
    "    for frame_faces in face_positions:\n",
    "        for x, y, w, h in frame_faces:\n",
    "            if w > 0 and h > 0:\n",
    "                center_x = x + w // 2\n",
    "                center_y = y + h // 2\n",
    "                cv2.circle(white_background, (center_x, center_y), 5, circle_color, -1)\n",
    "                # cv2.rectangle(white_background, (x, y), (x + w, y + h), rect_color, 2)\n",
    "\n",
    "    output_image_path = \"output_with_face_centers_and_lines_2.jpg\"\n",
    "    cv2.imwrite(output_image_path, white_background)\n",
    "    print(f\"Image saved to {output_image_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_files = [\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_1.mp4\",\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_2.mp4\",\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_3.mp4\",\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_4.mp4\",\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_5.mp4\",\n",
    "    \"C:/Users/hancomtst/Desktop/Nvidiaproject/data/ive_baddie_6.mp4\",\n",
    "]\n",
    "\n",
    "face_positions = load_video_data(video_files)\n",
    "draw_face_centers_on_white_background(face_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"No file found at {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Failed to open video file.\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps else 0\n",
    "\n",
    "    app = FaceAnalysis(\n",
    "        allowed_modules=[\"detection\", \"landmark_2d_106\"],\n",
    "        providers=[\"CUDAExecutionProvider\"],\n",
    "    )\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    window_name = \"Video\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    target_x = width // 2\n",
    "    target_y = height // 2\n",
    "\n",
    "    frame_count = 0\n",
    "    face_positions = []\n",
    "    face_recognitions = []\n",
    "    eye_endpoint = []\n",
    "\n",
    "    input_file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_video_path = f\"video_output_{input_file_name}.mp4\"\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # frame_count += 1\n",
    "        # if frame_count % 5 != 0:\n",
    "        #     continue\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        best_face = None\n",
    "        largest_face = None\n",
    "        largest_face_size = 0  # To track the largest face size\n",
    "\n",
    "        faces = app.get(frame)\n",
    "        for face in faces:\n",
    "            bbox = face.bbox.astype(int)\n",
    "            face_size = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "            # Update largest face if this face is bigger\n",
    "            if face_size > largest_face_size:\n",
    "                largest_face_size = face_size\n",
    "                largest_face = face\n",
    "\n",
    "            face_center_x = bbox[0] + (bbox[2] - bbox[0]) // 2\n",
    "            face_center_y = bbox[1] + (bbox[3] - bbox[1]) // 2\n",
    "\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2\n",
    "            )\n",
    "\n",
    "            distance = abs(face_center_x - target_x) + abs(face_center_y - target_y)\n",
    "            if best_face is None or distance < best_face[1]:\n",
    "                best_face = (face, distance)\n",
    "\n",
    "        if best_face is None and largest_face is not None:\n",
    "            best_face = (\n",
    "                largest_face,\n",
    "                0,\n",
    "            )  # Use the largest face if no face found in area\n",
    "\n",
    "        if best_face:\n",
    "            face = best_face[0]\n",
    "            bbox = face.bbox.astype(int)\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 4\n",
    "            )\n",
    "            if \"landmark_2d_106\" in face:\n",
    "                lmk = face.landmark_2d_106.astype(np.int64)\n",
    "                for point in lmk:\n",
    "                    cv2.circle(\n",
    "                        display_frame, tuple(point), 2, (0, 0, 255), -1, cv2.LINE_AA\n",
    "                    )\n",
    "                current_frame_positions = [\n",
    "                    (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "                ]\n",
    "                current_frame_face_data = [lmk.tolist()]\n",
    "                eye_point1 = tuple(lmk[35])\n",
    "                eye_point2 = tuple(lmk[93])\n",
    "                current_frame_eye_data = [(eye_point1, eye_point2)]\n",
    "\n",
    "                face_positions.append(current_frame_positions)\n",
    "                eye_endpoint.append(current_frame_eye_data)\n",
    "                face_recognitions.append(current_frame_face_data)\n",
    "\n",
    "        else:\n",
    "            # Append zeros if no face is detected\n",
    "            # Ensure that the structure matches the expected unpacking structure in CSV writing.\n",
    "            face_positions.append(\n",
    "                [(0, 0, 0, 0)]\n",
    "            )  # Enclose in an additional list to match structure\n",
    "            eye_endpoint.append([((0, 0), (0, 0))])  # Use tuple of tuples\n",
    "            face_recognitions.append([[]])  # This already matches expected structure\n",
    "\n",
    "        out.write(display_frame)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return (\n",
    "        face_positions,\n",
    "        eye_endpoint,\n",
    "        face_recognitions,\n",
    "        fps,\n",
    "        total_frames,\n",
    "        duration,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_files = [\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_1.mp4\",\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_2.mp4\",\n",
    "    # Add more video file paths here\n",
    "]\n",
    "\n",
    "for video_file in video_files:\n",
    "    process_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# TODO : 얼굴 크기가 큰 사람으로 선택할 때\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"No file found at {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Failed to open video file.\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps else 0\n",
    "\n",
    "    app = FaceAnalysis(\n",
    "        allowed_modules=[\"detection\", \"landmark_2d_106\"],\n",
    "        providers=[\"CUDAExecutionProvider\"],\n",
    "    )\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    window_name = \"Video\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    target_x = width // 2\n",
    "    target_y = height // 2\n",
    "\n",
    "    frame_count = 0\n",
    "    face_positions = []\n",
    "    face_recognitions = []\n",
    "    eye_endpoint = []\n",
    "\n",
    "    input_file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_video_path = f\"bigface_output_{input_file_name}.mp4\"\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        largest_face = None\n",
    "        largest_face_size = 0  # To track the largest face size\n",
    "\n",
    "        faces = app.get(frame)\n",
    "        for face in faces:\n",
    "            bbox = face.bbox.astype(int)\n",
    "            face_size = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
    "            # Update largest face if this face is bigger\n",
    "            if face_size > largest_face_size:\n",
    "                largest_face_size = face_size\n",
    "                largest_face = face\n",
    "\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2\n",
    "            )\n",
    "\n",
    "        if largest_face:\n",
    "            face = largest_face\n",
    "            bbox = face.bbox.astype(int)\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 4\n",
    "            )\n",
    "            if \"landmark_2d_106\" in face:\n",
    "                lmk = face.landmark_2d_106.astype(np.int64)\n",
    "                for point in lmk:\n",
    "                    cv2.circle(\n",
    "                        display_frame, tuple(point), 2, (0, 0, 255), -1, cv2.LINE_AA\n",
    "                    )\n",
    "                current_frame_positions = [\n",
    "                    (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "                ]\n",
    "                current_frame_face_data = [lmk.tolist()]\n",
    "                eye_point1 = tuple(lmk[35])\n",
    "                eye_point2 = tuple(lmk[93])\n",
    "                current_frame_eye_data = [(eye_point1, eye_point2)]\n",
    "\n",
    "                face_positions.append(current_frame_positions)\n",
    "                eye_endpoint.append(current_frame_eye_data)\n",
    "                face_recognitions.append(current_frame_face_data)\n",
    "\n",
    "        else:\n",
    "            # Append zeros if no face is detected\n",
    "            # Ensure that the structure matches the expected unpacking structure in CSV writing.\n",
    "            face_positions.append(\n",
    "                [(0, 0, 0, 0)]\n",
    "            )  # Enclose in an additional list to match structure\n",
    "            eye_endpoint.append([((0, 0), (0, 0))])  # Use tuple of tuples\n",
    "            face_recognitions.append([[]])  # This already matches expected structure\n",
    "\n",
    "        out.write(display_frame)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return (\n",
    "        face_positions,\n",
    "        eye_endpoint,\n",
    "        face_recognitions,\n",
    "        fps,\n",
    "        total_frames,\n",
    "        duration,\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_files = [\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_1.mp4\",\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_2.mp4\",\n",
    "    # Add more video file paths here\n",
    "]\n",
    "\n",
    "for video_file in video_files:\n",
    "    process_video(video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\1k3d68.onnx landmark_3d_68\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\genderage.onnx genderage\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "model ignore: C:\\Users\\hancomtst/.insightface\\models\\buffalo_l\\w600k_r50.onnx recognition\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "\n",
    "def process_video(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"No file found at {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Failed to open video file.\")\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / fps if fps else 0\n",
    "\n",
    "    app = FaceAnalysis(\n",
    "        allowed_modules=[\"detection\", \"landmark_2d_106\"],\n",
    "        providers=[\"CUDAExecutionProvider\"],\n",
    "    )\n",
    "    app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "    window_name = \"Video\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "    target_x = width // 2\n",
    "    target_y = height // 2\n",
    "    line1_x = int(width * 0.35)\n",
    "    line2_x = int(width * 0.65)\n",
    "\n",
    "    frame_count = 0\n",
    "    face_positions = []\n",
    "    face_recognitions = []\n",
    "    eye_endpoint = []\n",
    "\n",
    "    input_file_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "    output_video_path = f\"xlines_output_{input_file_name}.mp4\"\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while frame_count < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        display_frame = frame.copy()\n",
    "\n",
    "        # Draw the two vertical lines\n",
    "        cv2.line(display_frame, (line1_x, 0), (line1_x, height), (255, 255, 0), 2)\n",
    "        cv2.line(display_frame, (line2_x, 0), (line2_x, height), (255, 255, 0), 2)\n",
    "\n",
    "        best_face = None\n",
    "        smallest_distance = float(\"inf\")  # To track the smallest distance to the center\n",
    "\n",
    "        faces = app.get(frame)\n",
    "        for face in faces:\n",
    "            bbox = face.bbox.astype(int)\n",
    "            face_center_x = bbox[0] + (bbox[2] - bbox[0]) // 2\n",
    "\n",
    "            if line1_x <= face_center_x <= line2_x:\n",
    "                distance_to_center = abs(face_center_x - target_x)\n",
    "                if distance_to_center < smallest_distance:\n",
    "                    smallest_distance = distance_to_center\n",
    "                    best_face = face\n",
    "\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (255, 0, 0), 2\n",
    "            )\n",
    "\n",
    "        if best_face:\n",
    "            face = best_face\n",
    "            bbox = face.bbox.astype(int)\n",
    "            cv2.rectangle(\n",
    "                display_frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 0, 255), 4\n",
    "            )\n",
    "            if \"landmark_2d_106\" in face:\n",
    "                lmk = face.landmark_2d_106.astype(np.int64)\n",
    "                for point in lmk:\n",
    "                    cv2.circle(\n",
    "                        display_frame, tuple(point), 2, (0, 0, 255), -1, cv2.LINE_AA\n",
    "                    )\n",
    "                current_frame_positions = [\n",
    "                    (bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1])\n",
    "                ]\n",
    "                current_frame_face_data = [lmk.tolist()]\n",
    "                eye_point1 = tuple(lmk[35])\n",
    "                eye_point2 = tuple(lmk[93])\n",
    "                current_frame_eye_data = [(eye_point1, eye_point2)]\n",
    "\n",
    "                face_positions.append(current_frame_positions)\n",
    "                eye_endpoint.append(current_frame_eye_data)\n",
    "                face_recognitions.append(current_frame_face_data)\n",
    "\n",
    "        else:\n",
    "            # Append zeros if no face is detected\n",
    "            face_positions.append(\n",
    "                [(0, 0, 0, 0)]\n",
    "            )  # Enclose in an additional list to match structure\n",
    "            eye_endpoint.append([((0, 0), (0, 0))])  # Use tuple of tuples\n",
    "            face_recognitions.append([[]])  # This already matches expected structure\n",
    "\n",
    "        out.write(display_frame)\n",
    "\n",
    "        cv2.imshow(window_name, display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return (\n",
    "        face_positions,\n",
    "        eye_endpoint,\n",
    "        face_recognitions,\n",
    "        fps,\n",
    "        total_frames,\n",
    "        duration,\n",
    "    )\n",
    "\n",
    "\n",
    "# Example usage\n",
    "video_files = [\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_1.mp4\",\n",
    "    r\"C:/Users/hancomtst/Desktop/Nvidiaproject/data/pose_sync_ive_baddie_2.mp4\",\n",
    "    # Add more video file paths here\n",
    "]\n",
    "\n",
    "for video_file in video_files:\n",
    "    process_video(video_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
